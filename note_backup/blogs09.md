# Lecture 9 LLM and its Practices I

## In-class Material

1. [Slides](../slides/w9.pdf)

2. [Notebook](https://github.com/rz0718/BT5153_2024/tree/main/codes/lab_lecture09)

### Extra Reading

1. [Large Language Models: A Survey](https://arxiv.org/pdf/2402.06196.pdf)

2. [GPT1: Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

3. [GPT2: Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

4. [GPT3: Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)

5. [InstructGPT: Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155)

6. [Llama2](https://github.com/meta-llama/llama/tree/main)