# Lecture 8 Frontiers in NLP

## In-class Material

1. [Slides](../slides/w8.pdf)

2. [Notebook](../code/week8_nlp.zip) 

The colab version will be shared in the class. 

### Extra Reading

1. [Gensim Introduction](http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XJRo92gzaUk)

2. [Word2Vec Lecture by Chris Manning](https://www.youtube.com/watch?v=ERibwqs9p38)

3. [Visualization for graphs of nearest neighbors from high-dimensional word2vec embeddings](https://github.com/anvaka/word2vec-graph)

4. [Graph Embeddings](https://towardsdatascience.com/graph-embeddings-the-summary-cc6075aba007)

5. [Natural Language Processing: From Basics to using RNN and LSTM](https://towardsdatascience.com/natural-language-processing-from-basics-to-using-rnn-and-lstm-ef6779e4ae66)

6. [An Overview of the main concepts of Word2Vec, GloVe, and FastText](http://hunterheidenreich.com/blog/intro-to-word-embeddings/)

7. [NLP Learning Series](https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/)

8. [Transfer Learning in NLP](https://docs.google.com/presentation/d/1LsUAhR_qIVbq6xH6Aw4ag8MGB_-UWfd0KoVhtTgye6o/edit?usp=sharing)

9. [RNN vs Autoregressive Models: Transformer](https://bair.berkeley.edu/blog/2018/08/06/recurrent/)

10. [Awesome BERT & Transfer Learning in NLP ](https://github.com/cedrickchee/awesome-bert-nlp)

11. [Why BERT Fails In Commercial Environments](https://www.intel.ai/bert-commercial-environments/)

12. [RNN Tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)

13. [When Recurrent Models Don't Need to be Recurrent](https://bair.berkeley.edu/blog/2018/08/06/recurrent/)

13. [The Time Series Transformer](https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3)

14. [Applying massive language models in the real world with Cohere](http://jalammar.github.io/applying-large-language-models-cohere/)