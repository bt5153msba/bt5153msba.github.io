# Lecture 7 From BoW to Word2Vec

## In-class Material

1. [Slides](../slides/w7.pdf)

2. [Notebook](https://github.com/rz0718/BT5153_2024/tree/main/codes/lab_lecture07)

### Extra Reading

1. [Gensim Introduction](http://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.XJRo92gzaUk)

2. [Word2Vec Lecture by Chris Manning](https://www.youtube.com/watch?v=ERibwqs9p38)

3. [Visualization for graphs of nearest neighbors from high-dimensional word2vec embeddings](https://github.com/anvaka/word2vec-graph)

4. [Graph Embeddings](https://towardsdatascience.com/graph-embeddings-the-summary-cc6075aba007)

5. [Natural Language Processing: From Basics to using RNN and LSTM](https://towardsdatascience.com/natural-language-processing-from-basics-to-using-rnn-and-lstm-ef6779e4ae66)

6. [An Overview of the main concepts of Word2Vec, GloVe, and FastText](http://hunterheidenreich.com/blog/intro-to-word-embeddings/)

7. [NLP Learning Series](https://mlwhiz.com/blog/2019/01/17/deeplearning_nlp_preprocess/)

8. [Transfer Learning in NLP](https://docs.google.com/presentation/d/1LsUAhR_qIVbq6xH6Aw4ag8MGB_-UWfd0KoVhtTgye6o/edit?usp=sharing)